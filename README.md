# üè† Aplica√ß√£o de Modelos de Linguagem (LLMs) no desenvolvimento de um sistema de busca de apartamentos para aluguel em Jaragu√° do Sul/SC

## 1. Descri√ß√£o geral (objetivo e motiva√ß√£o)
Foi desenvolvido um sistema inteligente, baseado em Modelos de Linguagem de Grande Escala (LLMs), para a busca de im√≥veis dispon√≠veis para loca√ß√£o no munic√≠pio de Jaragu√° do Sul. O sistema ter√° como finalidade possibilitar a intera√ß√£o em linguagem natural, de modo que o usu√°rio possa expressar suas necessidades habitacionais de forma simples e intuitiva, enquanto a intelig√™ncia artificial processa essas informa√ß√µes para realizar buscas mais precisas e personalizadas.

## 2. Motiva√ß√£o
- A solu√ß√£o foi desenvolvida para resolver o problema da classifica√ß√£o e busca inteligente de propriedades imobili√°rias, motivada pela necessidade de incorporar modelos de linguagem (LLMs) capazes de interpretar prefer√™ncias de usu√°rios e realizar consultas sem√¢nticas de forma aut√¥noma e contextualizada.
- √â combinado  m√∫ltiplos agentes de IA (CrewAI + LangChain + Gemini) para interpretar linguagem natural, estruturar consultas e retornar im√≥veis compat√≠veis com os crit√©rios fornecidos. O uso do servidor MCP permite modularidade e flexibilidade, enquanto a API centraliza a orquestra√ß√£o do fluxo de dados.

## 3. Arquitetura
A aplica√ß√£o adota uma arquitetura baseada no Modelo C4, composta pelos seguintes elementos:

- Front-end: React
- Back-end: FastAPI
- Banco de Dados: MongoDB
- IA: LLM + servidor MCP
- Comunica√ß√£o: HTTP/JSON

## 4. Como rodar o projeto (passo a passo)
#### Pr√©-requisitos: 
- Node.js
- Python 3.10+
- MongoDB
- Pip ou uv
- Chaves de API (OpenAI, HuggingFace, etc.)

#### Instru√ß√µes
- Front-end
```
cd front-end
npm install
npm run dev
```
- Backend
```
cd rest_api
pip install -r requirements.txt
uvicorn app.main:app --reload
```

- Vari√°veis de ambiente

```
Criar um arquivo .env com:
ALLOW_ORIGIN="http://localhost:1234"
MONGO_URI="example_public_mongo_uri"
GOOGLE_API_KEY="example_public_google_api_key"
```

## 5. Implementa√ß√£o
- Render - backend: https://tcc-hx03.onrender.com
- Vercel - frontend: https://tcc-indol-tau.vercel.app/

## 6. Requisitos de Software
#### Requisitos Funcionais(RF): 
```
1. RF001 ‚Äì O sistema deve permitir que o usu√°rio realize a busca por im√≥veis utilizando linguagem natural.
2. RF002 ‚Äì O sistema deve disponibilizar uma interface de navega√ß√£o que exiba os resultados conforme os crit√©rios solicitados.
3. RF003 ‚Äì O sistema deve possibilitar que o usu√°rio entre em contato com a imobili√°ria respons√°vel pelo im√≥vel, mediante redirecionamento para o n√∫mero ou canal de contato.
4. RF004 ‚Äì O sistema deve permitir m√∫ltiplas intera√ß√µes, de modo que o usu√°rio possa realizar quantas buscas considerar necess√°rias.
```
#### Requisitos N√£o-Funcionais (RNF):
```
1. RNF001 ‚Äì O sistema deve retornar, no m√≠nimo, um im√≥vel por consulta realizada.
2. RNF002 ‚Äì O sistema deve utilizar um LLM de baixo custo operacional e de f√°cil manuten√ß√£o (ex.: LLaMA 3 via Groq).
3. RNF003 ‚Äì A interface deve ser simples, responsiva e acess√≠vel via navegador, permitindo a correta visualiza√ß√£o das informa√ß√µes em diferentes tamanhos de tela.
```
## 7. Hist√≥rico de Decis√µes
1. Ado√ß√£o do FastAPI como framework de back-end
Optou-se pelo FastAPI devido √† sua elevada performance, suporte nativo a programa√ß√£o ass√≠ncrona e forte tipagem baseada em Pydantic. Esses fatores permitiram a constru√ß√£o de uma API robusta, com valida√ß√£o autom√°tica de dados, documenta√ß√£o integrada e baixo tempo de resposta, aspectos essenciais para uma aplica√ß√£o que integra modelos de IA e opera√ß√µes de busca vetorial.

2. Utiliza√ß√£o de um LLM para processamento sem√¢ntico
A escolha de empregar um modelo de linguagem (LLM) foi motivada pela necessidade de interpretar prefer√™ncias dos usu√°rios de forma contextual e realizar transforma√ß√µes sem√¢nticas que possibilitam consultas mais precisas. O LLM atua como componente central na gera√ß√£o do vetor de busca, na extra√ß√£o de inten√ß√µes e na coordena√ß√£o entre agentes internos.

3. Introdu√ß√£o do servidor MCP como ponte entre a API e ferramentas externas
O servidor MCP foi adotado como mecanismo facilitador da comunica√ß√£o entre o LLM e as ferramentas respons√°veis por executar tarefas espec√≠ficas, como a gera√ß√£o de vetores de busca e a execu√ß√£o de agrega√ß√µes no banco de dados. Essa abordagem modular melhora a escalabilidade, permitindo a adi√ß√£o de novas capacidades sem alterar o n√∫cleo da aplica√ß√£o.

4. Defini√ß√£o de um pipeline de busca baseado em agrega√ß√µes
A realiza√ß√£o da consulta √†s propriedades por meio de agrega√ß√µes foi escolhida por oferecer maior flexibilidade na defini√ß√£o de etapas de busca, filtragem e sele√ß√£o de campos retornados. Essa arquitetura permite otimizar a precis√£o da recomenda√ß√£o e ajustar os crit√©rios conforme a evolu√ß√£o do projeto.

5. Padroniza√ß√£o da comunica√ß√£o entre componentes via JSON/HTTP
Estabeleceu-se que a comunica√ß√£o entre o front-end, API, LLM e MCP ocorreria por meio de requisi√ß√µes HTTP utilizando JSON como formato de troca. A decis√£o prioriza interoperabilidade, simplicidade e compatibilidade com diferentes tecnologias e ambientes de implanta√ß√£o.

## 8. Modelagem 
### Caso de Uso
```
Caso de Uso 1 ‚Äî Buscar im√≥veis para loca√ß√£o

Ator principal: Usu√°rio Objetivo: Consultar im√≥veis dispon√≠veis conforme prefer√™ncias. 
Fluxo principal:
Usu√°rio insere comandos em linguagem natural.
Sistema interpreta crit√©rios (ex.: pre√ßo, localiza√ß√£o, n√∫mero de quartos).
Sistema recupera dados da base.
Sistema apresenta lista filtrada ao usu√°rio.
```

```
####  Caso de Uso 2 ‚Äî Atualiza√ß√£o autom√°tica da base de im√≥veis

Ator principal: Sistema Objetivo: Atualizar periodicamente os im√≥veis dispon√≠veis. 
Fluxo principal:
Sistema acessa API da imobili√°ria.
Dados s√£o extra√≠dos e validados.
Registros desatualizados s√£o removidos.
Banco √© atualizado.
```

```
#### Caso de Uso 3 ‚Äî Intera√ß√£o com o LLM

Ator principal: Sistema Objetivo: Interpretar solicita√ß√µes feitas em linguagem natural. 
Fluxo principal:
Comando do usu√°rio √© enviado ao LLM Gemini.
LLM interpreta e converte para par√¢metros estruturados.
Sistema executa consulta com base na interpreta√ß√£o.
```
## 9. BPMN (Descri√ß√£o textual)
- Usu√°rio ‚Üí envia comando ‚Üí Frontend
- Frontend ‚Üí envia requisi√ß√£o ‚Üí API FastAPI
- API ‚Üí envia texto ‚Üí LLM Gemini
- LLM ‚Üí retorna par√¢metros ‚Üí Servidor MCP
- Servidor MCP ‚Üí executa busca ‚Üí Banco de Dados
- Banco ‚Üí retorna resultados ‚Üí MCP ‚Üí API ‚Üí Frontend

## 10. Diagrama de arquitetura
#### N√≠vel 1 ‚Äî Diagrama de Contexto

O sistema recebe comandos do usu√°rio, interpreta via LLM Gemini, consulta o banco por meio do MCP e retorna resultados para o usu√°rio.

#### N√≠vel 2 ‚Äî Diagrama de Containers

Frontend (React): interface
API (FastAPI): orquestra chamadas
LLM Gemini: interpreta√ß√£o sem√¢ntica
Servidor MCP: execu√ß√£o de ferramentas
Banco de Dados: armazenamento e atualiza√ß√£o di√°ria

####  N√≠vel 3 ‚Äî Componentes

- Componente de Rotas: /properties
- Componente de Interpreta√ß√£o: agente LLM
- Componente de Busca: ferramenta get_properties
- Componente de Atualiza√ß√£o: rotina di√°ria da API

####  N√≠vel 4 ‚Äî C√≥digo

- api/routes/user_routes.py ‚Äì rotas de usu√°rio
- api/services/user_service.py ‚Äì regras de neg√≥cio
- api/models/user_model.py ‚Äì modelo de dados
- frontend/src/pages/Home.jsx ‚Äì tela inicial
- frontend/src/services/api.js ‚Äì comunica√ß√£o com API